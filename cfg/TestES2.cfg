# General-purpose settings.
verbose = false
logPath = /home/justin/dev/oppt_cyber/log
overwriteExistingLogFiles = true
saveParticles = false

[plugins]
heuristicPlugin = libCyberHeuristicPlugin.so

planningRewardPlugin = libCyberRewardPlugin.so
executionRewardPlugin = libCyberRewardPlugin.so

planningTerminalPlugin = libCyberTerminalPlugin.so
executionTerminalPlugin = libCyberTerminalPlugin.so

planningTransitionPlugin = libCyberTransitionPlugin.so
executionTransitionPlugin = libCyberTransitionPlugin.so

planningObservationPlugin = libCyberObservationPlugin.so
executionObservationPlugin = libCyberObservationPlugin.so

executionInitialBeliefPlugin = libCyberInitialBeliefPlugin.so
planningInitialBeliefPlugin = libCyberInitialBeliefPlugin.so

[cyberScenarioOptions]
scenarioPath = /home/justin/dev/oppt_cyber/scenarios/es2_red_d.yaml
minReward = -10
maxReward = 989

[state]
additionalDimensions = 7
additionalDimensionLimits = [[0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1]]

[action]
additionalDimensions = 1
additionalDimensionLimits = [[0, 7]]

[observation]
additionalDimensions = 1
additionalDimensionLimits = [[-1, 1]]

[changes]

[problem]
nRuns = 1
nSteps = 100
robotName = CyberAgent
enableGazeboStateLogging = false
discountFactor = 0.95
stepTimeout = 3000

[ABT]
# The number of trajectories to simulate per time step (0 => wait for timeout)
historiesPerStep = 0

# If this is set to "true", ABT will prune the tree after every step.
pruneEveryStep = true

# If this is set to "true", ABT will reset the tree instead of modifying it when
# changes occur.
resetOnChanges = false

# The particle filter to use
particleFilter = observationModel

# The minimum number of particles for the current belief state in a simulation.
# Extra particles will be resampled via a particle filter if the particle count
# for the *current* belief state drops below this number during simulation.
minParticleCount = 5000

# True if the above horizon is relative to the initial belief, and false
# if it's relative to the current belief.
isAbsoluteHorizon = false

searchStrategy = ucb(10.0)

estimator = max()

heuristicTimeout = 0.1

savePolicy = false
loadInitialPolicy = false
policyPath = final-0.pol

actionType = discrete
numInputStepsActions = 8

observationType = discrete
numInputStepsObservations = 3

# The maximum L2-distance between observations for them to be considered similar
maxObservationDistance = 0.0005

[simulation]
interactive = false
particlePlotLimit = 0